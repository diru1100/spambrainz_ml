{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LodBrok model\n",
    "\n",
    "\n",
    "LodBrok is an LSTM model trained to detect the editor spam accounts in [MusicBrainz](https://musicbrainz.org/doc/MusicBrainz_Database/Schema). The model trained so far is done through offline batch training on private editor dataset and will be integrated with [MusicBrainz](https://musicbrainz.org/) project through [SpamNinja](https://tickets.metabrainz.org/browse/MBS-9480) feature in the future.\n",
    "\n",
    "## Network layout\n",
    "![Lodbrok network layout](lodbrok.png)\n",
    "\n",
    "Lodbrok receives four different inputs which are sub-arrays of the pre-processed input datum. The website and email inputs have respectively been tokenized to their top 1024 entries and are embedded into 256-dimensional vectors. Meanwhile the user biography input is just reshaped into one 512-dimensional vector, as it is already quasi-embedded.\n",
    "\n",
    "All three inputs are then passed into LSTMs where the bio-LSTM has an output twice as large as the others.\n",
    "\n",
    "The outputs of the LSTMS are then concatenated with the other inputs (area set, non-zero privs, bio length, etc.) and passed into a stack of two fully-connected layers with 64 neurons and 50% dropout each.\n",
    "\n",
    "The output layer consists of two neurons that represent the classification confidence for each category (spam and non-spam) and are activated using softmax so that their sum will always be one.\n",
    "\n",
    "\n",
    "## Working\n",
    "\n",
    "### Requirements\n",
    "\n",
    "The only requirements are:  \n",
    "1) Jupyter Notebook  \n",
    "2) Keras with Tensorflow Backend  \n",
    "\n",
    "The model is trained on editor account details like name, website, bio etc. As the model takes input as integers, the data is preprocessed to numbers as follows:\n",
    "\n",
    "### Data preprocssing\n",
    "\n",
    "```\n",
    "data = np.array([\n",
    "        1,#spam classification(spam or not)\n",
    "        1,# Area Set\n",
    "        1,# Gender given\n",
    "        1,# Birth date set(bool)\n",
    "        1,# Nonzero editor privs(bool)\n",
    "        0,# Bio length\n",
    "        0,#bio_urls, # URLs in bio\n",
    "        -2,#conf_delta, # Confirmation delta\n",
    "        -2,# Last updated delta\n",
    "        -2,#Last login delta\n",
    "        1,# Email domain\n",
    "        1,#website_token, # Website domain\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "```\n",
    "\n",
    "This is then combined with bio and after converting the whole dataset it is then kept in a pickle file \n",
    "\n",
    "```\n",
    "data = np.concatenate((data, bio))\n",
    "\n",
    "with open(\"SENSITIVE/spambrainz_dataset.pickle\", \"wb\") as f:\n",
    "    pickle.dump(data, f)\n",
    "```\n",
    "\n",
    "### Model training\n",
    "\n",
    "The pickle file is then used in the model to train:\n",
    "```\n",
    "m = get_model()\n",
    "train_model(model, training_data, [tensorboard])\n",
    "```\n",
    " \n",
    "After training the model, the model obtained is saved to be used later:\n",
    " ```\n",
    " model.save(\"lodbrok1.h5\")\n",
    " ```\n",
    "This will store the model in a h5 type file, which later can be used to load the model for evaluation. The summary of the trained model is as follows:\n",
    "![](summary.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "\n",
    "Another pickle file is created to test the model that we trained, this is stored in test.pickle file. It is then evaluated with the model we saved earlier. The below code demonstrates how it is done:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import load_model\n",
    "import keras\n",
    "from utils.evaluation import evaluate, print_stats\n",
    "eval = evaluate(\"lodbrok1.h5\", \"test.pickle\")\n",
    "print_stats(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code evaluates the trained model against the tested data. The files \"lodbrok1.h5\" is used to load the model and \"test.pickle\" consists the test data. This is the result of evaluation done:\n",
    "![](eval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary the Lodbrok model achieves a very high spam detection rate while simultaneously maintaining a low false positive rate. Data falsely classified by the model should be further examined to determine whether it really is part of the right dataset or whether there is a deficit of a certain type of data.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
